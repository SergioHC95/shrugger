{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Combined Experiment\n",
    "\n",
    "This notebook demonstrates how to run the combined experiment that collects both Likert evaluation results and hidden states in a single pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add the project root to the path to allow imports\n",
    "repo_root = Path.cwd()\n",
    "if not (repo_root / \"abstainer\").exists():\n",
    "    repo_root = repo_root.parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Suppress tqdm warnings about ipywidgets\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tqdm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions\n",
    "from abstainer.src.experiment import load_combined_results, run_combined_experiment\n",
    "from abstainer.src.experiment_utils import get_questions_by_filter\n",
    "from abstainer.src.model import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure the experiment parameters\n",
    "\n",
    "Set up your experiment parameters below. You can customize:\n",
    "- Model ID\n",
    "- Question filters (subject, difficulty, split)\n",
    "- Prompt form (V0-V5 for different description styles)\n",
    "- Custom labels for the Likert options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_id = \"google/gemma-3-4b-it\"  # Replace with your model\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\"./results/minimal_experiment\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Question filters (set to None to include all)\n",
    "subject = \"Physics\"     # Filter by subject: \"Physics\", \"Biology\", etc.\n",
    "difficulty = None       # Filter by difficulty: \"1\", \"2\", \"3\", etc.\n",
    "split = \"dev\"           # Filter by split: \"train\", \"dev\", \"test\"\n",
    "\n",
    "# Prompt configuration\n",
    "form = \"V2\"             # Choose description style: \"V0\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\"\n",
    "                        # V0: \"Definitely yes/no\"\n",
    "                        # V1: \"Yes/No, I'm sure\"\n",
    "                        # V2: \"Certainly yes/no\"\n",
    "                        # V3: \"Yes/No, absolutely\"\n",
    "                        # V4: \"Strongly yes/no\"\n",
    "                        # V5: \"Yes/No, without doubt\"\n",
    "\n",
    "# Custom labels (set to None to use default A-E)\n",
    "labels = [\"A\", \"B\", \"C\", \"D\", \"E\"]  # Labels in order: definitely_yes, probably_yes, not_sure, probably_no, definitely_no\n",
    "# Alternative examples:\n",
    "# labels = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "# labels = [\"YES\", \"LIKELY\", \"UNSURE\", \"UNLIKELY\", \"NO\"]\n",
    "\n",
    "# Experiment control\n",
    "force_reprocess = True  # Set to False to use existing results if available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model and get questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(f\"Loading model: {model_id}\")\n",
    "tokenizer, model = load_model(model_id)\n",
    "\n",
    "# Get questions based on filters\n",
    "questions = get_questions_by_filter(\n",
    "    subject=subject,\n",
    "    difficulty=difficulty,\n",
    "    split=split\n",
    ")\n",
    "\n",
    "print(f\"Found {len(questions)} questions matching filters\")\n",
    "\n",
    "# Display a few example questions\n",
    "if questions:\n",
    "    for i, q in enumerate(questions[:3]):\n",
    "        print(f\"\\nQuestion {i+1}: {q['question']}\")\n",
    "        print(f\"ID: {q['id']}, Subject: {q['subject']}, Difficulty: {q['difficulty']}\")\n",
    "else:\n",
    "    print(\"No questions found matching the filters. Try different filter criteria.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the combined experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the combined experiment\n",
    "print(f\"Running combined experiment with form '{form}'...\")\n",
    "if labels:\n",
    "    print(f\"Using custom labels: {labels}\")\n",
    "\n",
    "results = run_combined_experiment(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    output_dir=str(output_dir),\n",
    "    questions=questions,\n",
    "    form=form,\n",
    "    labels=labels,\n",
    "    verbose=True,\n",
    "    force_reprocess=force_reprocess\n",
    ")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nExperiment completed!\")\n",
    "print(f\"Likert evaluation: {results['likert_stats']['completed_questions']} questions processed\")\n",
    "if 'average_score' in results['likert_stats']:\n",
    "    print(f\"Average score: {results['likert_stats']['average_score']:.2f}\")\n",
    "print(f\"Score distribution: {results['likert_stats']['score_distribution']}\")\n",
    "print(f\"Hidden states: {results['hidden_stats']['completed_questions']} questions processed\")\n",
    "print(f\"Hidden state shape: {results['hidden_stats']['hidden_state_shape']}\")\n",
    "\n",
    "# Output file paths\n",
    "print(\"\\nOutput files:\")\n",
    "for name, path in results[\"output_files\"].items():\n",
    "    print(f\"- {name}: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and analyze results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "data = load_combined_results(str(output_dir), form=form)\n",
    "\n",
    "print(f\"Loaded {len(data['likert_results'])} Likert results\")\n",
    "print(f\"Loaded {len(data['hidden_states'])} hidden state tensors\")\n",
    "\n",
    "# Example: Look at the first question\n",
    "if data['likert_results']:\n",
    "    first_qid = next(iter(data['likert_results']))\n",
    "    result = data['likert_results'][first_qid]\n",
    "    hidden_state = data['hidden_states'].get(first_qid)\n",
    "\n",
    "    print(f\"\\nExample question (ID: {first_qid}):\")\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(f\"Predicted label: {result['pred_label']}\")\n",
    "    print(f\"Canonical label: {result['canonical_label']}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "\n",
    "    if hidden_state is not None:\n",
    "        print(f\"Hidden state shape: {hidden_state.shape}\")\n",
    "\n",
    "        # Example: Show normalized probabilities for this question\n",
    "        print(\"\\nProbabilities:\")\n",
    "        for label, prob in result['probs_norm'].items():\n",
    "            print(f\"  {label}: {prob:.4f}\")\n",
    "\n",
    "        print(\"\\nCanonical probabilities:\")\n",
    "        for label, prob in result['canonical_probs_norm'].items():\n",
    "            print(f\"  {label}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize hidden states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hidden states for a question\n",
    "if data['hidden_states'] and first_qid in data['hidden_states']:\n",
    "    hidden_state = data['hidden_states'][first_qid]\n",
    "\n",
    "    # 1. Use a logarithmic normalization to better visualize the range of values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(hidden_state, aspect='auto', cmap='inferno', norm=plt.matplotlib.colors.LogNorm())\n",
    "    plt.colorbar(label='Activation (log scale)')\n",
    "    plt.title(f\"Hidden State Activations for Question {first_qid} - Log Scale\")\n",
    "    plt.xlabel(\"Hidden Dimension\")\n",
    "    plt.ylabel(\"Layer\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Normalize each layer to highlight relative activations within layers\n",
    "    normalized_state = np.zeros_like(hidden_state)\n",
    "    for i in range(hidden_state.shape[0]):\n",
    "        layer = hidden_state[i]\n",
    "        layer_min, layer_max = layer.min(), layer.max()\n",
    "        if layer_max > layer_min:  # Avoid division by zero\n",
    "            normalized_state[i] = (layer - layer_min) / (layer_max - layer_min)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(normalized_state, aspect='auto', cmap='inferno')\n",
    "    plt.colorbar(label='Normalized Activation')\n",
    "    plt.title(\"Layer-Normalized Hidden State Activations\")\n",
    "    plt.xlabel(\"Hidden Dimension\")\n",
    "    plt.ylabel(\"Layer\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Focus on the interesting region around dimension 450\n",
    "    interesting_region = hidden_state[:, 400:500]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(interesting_region, aspect='auto', cmap='inferno')\n",
    "    plt.colorbar(label='Activation')\n",
    "    plt.title(\"Focused View of Dimensions 400-500\")\n",
    "    plt.xlabel(\"Hidden Dimension (offset by 400)\")\n",
    "    plt.ylabel(\"Layer\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Plot the average activation per layer\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    layer_means = hidden_state.mean(axis=1)\n",
    "    plt.plot(layer_means)\n",
    "    plt.title(\"Mean Activation by Layer\")\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"Mean Activation\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Plot the standard deviation of activations per layer\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    layer_stds = hidden_state.std(axis=1)\n",
    "    plt.plot(layer_stds)\n",
    "    plt.title(\"Activation Standard Deviation by Layer\")\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"Standard Deviation\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare correct vs. incorrect predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare hidden states for correct vs. incorrect predictions\n",
    "correct_ids = [qid for qid, result in data['likert_results'].items() if result['score'] > 0]\n",
    "incorrect_ids = [qid for qid, result in data['likert_results'].items() if result['score'] < 0]\n",
    "\n",
    "print(f\"Number of correct predictions: {len(correct_ids)}\")\n",
    "print(f\"Number of incorrect predictions: {len(incorrect_ids)}\")\n",
    "\n",
    "# Function to compute average hidden state across a set of question IDs\n",
    "def compute_avg_hidden_state(question_ids):\n",
    "    if not question_ids:\n",
    "        return None\n",
    "\n",
    "    # Get hidden states for the specified questions\n",
    "    hidden_states = [data['hidden_states'][qid] for qid in question_ids if qid in data['hidden_states']]\n",
    "\n",
    "    if not hidden_states:\n",
    "        return None\n",
    "\n",
    "    # Stack and average\n",
    "    return np.mean(np.stack(hidden_states), axis=0)\n",
    "\n",
    "# Only proceed if we have both correct and incorrect examples\n",
    "if correct_ids and incorrect_ids:\n",
    "    # Compute average hidden states\n",
    "    avg_correct = compute_avg_hidden_state(correct_ids)\n",
    "    avg_incorrect = compute_avg_hidden_state(incorrect_ids)\n",
    "\n",
    "    if avg_correct is not None and avg_incorrect is not None:\n",
    "        # Compute difference between correct and incorrect\n",
    "        diff = avg_correct - avg_incorrect\n",
    "\n",
    "        # Plot the norm of the difference across layers\n",
    "        layer_norms = np.linalg.norm(diff, axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(layer_norms)\n",
    "        plt.title(\"Difference between correct and incorrect predictions across layers\")\n",
    "        plt.xlabel(\"Layer\")\n",
    "        plt.ylabel(\"L2 Norm of difference\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abstainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
