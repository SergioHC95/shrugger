{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Experiment: Likert Evaluation and Hidden States Collection\n",
    "\n",
    "This notebook demonstrates how to run an experiment that combines both Likert evaluation with custom labels and the collection of residual stream data for all questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add the project root to the path to allow imports\n",
    "repo_root = Path.cwd().parent\n",
    "if not (repo_root / \"abstainer\").exists():\n",
    "    repo_root = Path.cwd()\n",
    "sys.path.insert(0, str(repo_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstainer.src.experiment import (\n",
    "    load_hidden_states,\n",
    "    run_hidden_states_experiment,\n",
    "    run_likert_experiment,\n",
    ")\n",
    "from abstainer.src.experiment_utils import get_questions_by_filter\n",
    "from abstainer.src.model import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure the Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "model_id = \"google/gemma-3-4b-it\"  # Replace with your model\n",
    "output_dir = Path(\"./results/combined_experiment\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Question filters\n",
    "subject = \"Physics\"  # Optional: filter by subject\n",
    "difficulty = 3    # Optional: filter by difficulty\n",
    "split = \"dev\"       # Optional: use train split\n",
    "\n",
    "# Likert form configuration\n",
    "form = \"V0_letters\"  # Likert form to use\n",
    "\n",
    "# Custom labels for Likert options\n",
    "# These are the actual tokens the model will generate as responses\n",
    "# They should be single tokens in the model's vocabulary for best results\n",
    "custom_labels = [\n",
    "    \"A\",  # Definitely Yes\n",
    "    \"B\",  # Probably Yes\n",
    "    \"C\",  # Not Sure\n",
    "    \"D\",  # Probably No\n",
    "    \"E\"   # Definitely No\n",
    "]\n",
    "\n",
    "# Define output files\n",
    "likert_output = output_dir / f\"likert_results_{form}.json\"\n",
    "hidden_states_output = output_dir / f\"hidden_states_{form}.npz\"\n",
    "\n",
    "print(f\"Experiment configured with model: {model_id}\")\n",
    "print(f\"Subject: {subject}, Split: {split}\")\n",
    "print(f\"Using form: {form}\")\n",
    "print(f\"Custom labels: {custom_labels}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Custom Labels in Likert Prompts\n",
    "\n",
    "The `custom_labels` parameter in `run_likert_experiment` allows you to specify the exact tokens that will be used as options in the Likert scale prompt. These tokens are what the model will generate as its response.\n",
    "\n",
    "For example, with the default \"V0_letters\" form and custom_labels=[\"A\", \"B\", \"C\", \"D\", \"E\"], the prompt will look like:\n",
    "\n",
    "```\n",
    "Question: Is the Earth round?\n",
    "\n",
    "A) Definitely yes\n",
    "B) Probably yes\n",
    "C) Not sure\n",
    "D) Probably no\n",
    "E) Definitely no\n",
    "\n",
    "Respond with exactly one token.\n",
    "Answer:\n",
    "```\n",
    "\n",
    "The model will then generate one of these tokens as its response. The mapping from these tokens to the universal format (YY, Y, A, N, NN) is handled automatically.\n",
    "\n",
    "Important notes:\n",
    "1. The custom labels should ideally be single tokens in the model's vocabulary\n",
    "2. The order matters: [definitely_yes, probably_yes, not_sure, probably_no, definitely_no]\n",
    "3. You must provide exactly 5 labels\n",
    "4. Using tokens that are already in the model's vocabulary will give the best results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(f\"Loading model: {model_id}\")\n",
    "tokenizer, model = load_model(model_id)\n",
    "\n",
    "# Get questions based on filters\n",
    "questions = get_questions_by_filter(\n",
    "    subject=subject,\n",
    "    difficulty=difficulty,\n",
    "    split=split\n",
    ")\n",
    "\n",
    "print(f\"Found {len(questions)} questions matching filters\")\n",
    "\n",
    "# Display a few example questions\n",
    "for i, q in enumerate(questions[:3]):\n",
    "    print(f\"\\nQuestion {i+1}: {q['question']}\")\n",
    "    print(f\"ID: {q['id']}, Subject: {q['subject']}, Difficulty: {q['difficulty']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Likert Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Likert experiment\n",
    "print(f\"Running Likert experiment with form '{form}'...\")\n",
    "if custom_labels:\n",
    "    print(f\"Using custom labels: {custom_labels}\")\n",
    "\n",
    "likert_stats = run_likert_experiment(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    output_file=str(likert_output),\n",
    "    questions=questions,\n",
    "    form=form,\n",
    "    labels=custom_labels,  # Pass the custom labels to use for Likert options\n",
    "    verbose=True,\n",
    "    force_reprocess=True  # Set to False if you want to resume from existing results\n",
    ")\n",
    "\n",
    "print(f\"\\nLikert experiment completed: {likert_stats['completed_questions']} questions processed\")\n",
    "print(f\"Average score: {likert_stats.get('average_score')}\")\n",
    "print(f\"Score distribution: {likert_stats.get('score_distribution')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collect Hidden States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hidden states experiment\n",
    "print(\"Collecting hidden states...\")\n",
    "\n",
    "hidden_stats = run_hidden_states_experiment(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    output_file=str(hidden_states_output),\n",
    "    questions=questions,\n",
    "    verbose=True,\n",
    "    force_reprocess=True  # Set to False if you want to resume from existing results\n",
    ")\n",
    "\n",
    "print(f\"\\nHidden states collection completed: {hidden_stats['completed_questions']} questions processed\")\n",
    "print(f\"Hidden state shape: {hidden_stats['hidden_state_shape']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Experiment Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save experiment configuration\n",
    "config = {\n",
    "    \"model_id\": model_id,\n",
    "    \"subject\": subject,\n",
    "    \"difficulty\": difficulty,\n",
    "    \"split\": split,\n",
    "    \"form\": form,\n",
    "    \"custom_labels\": custom_labels,\n",
    "    \"likert_results_file\": str(likert_output),\n",
    "    \"hidden_states_file\": str(hidden_states_output),\n",
    "    \"likert_stats\": likert_stats,\n",
    "    \"hidden_stats\": hidden_stats\n",
    "}\n",
    "\n",
    "config_file = output_dir / \"experiment_config.json\"\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Experiment configuration saved to {config_file}\")\n",
    "print(f\"Likert results saved to {likert_output}\")\n",
    "print(f\"Hidden states saved to {hidden_states_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the hidden states data\n",
    "hidden_data = load_hidden_states(str(hidden_states_output))\n",
    "\n",
    "# Load the Likert results\n",
    "with open(likert_output, encoding='utf-8') as f:\n",
    "    likert_results = json.load(f)\n",
    "\n",
    "print(f\"Loaded hidden states for {len(hidden_data['hidden_states'])} questions\")\n",
    "print(f\"Loaded Likert results for {len(likert_results)} questions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example analysis: Compare hidden states for correct vs. incorrect predictions\n",
    "correct_ids = [qid for qid, result in likert_results.items() if result['score'] > 0]\n",
    "incorrect_ids = [qid for qid, result in likert_results.items() if result['score'] < 0]\n",
    "\n",
    "print(f\"Number of correct predictions: {len(correct_ids)}\")\n",
    "print(f\"Number of incorrect predictions: {len(incorrect_ids)}\")\n",
    "\n",
    "# Function to compute average hidden state across a set of question IDs\n",
    "def compute_avg_hidden_state(question_ids):\n",
    "    if not question_ids:\n",
    "        return None\n",
    "\n",
    "    # Get hidden states for the specified questions\n",
    "    hidden_states = [hidden_data['hidden_states'][qid] for qid in question_ids if qid in hidden_data['hidden_states']]\n",
    "\n",
    "    if not hidden_states:\n",
    "        return None\n",
    "\n",
    "    # Stack and average\n",
    "    return np.mean(np.stack(hidden_states), axis=0)\n",
    "\n",
    "# Compute average hidden states\n",
    "avg_correct = compute_avg_hidden_state(correct_ids)\n",
    "avg_incorrect = compute_avg_hidden_state(incorrect_ids)\n",
    "\n",
    "if avg_correct is not None and avg_incorrect is not None:\n",
    "    # Compute difference between correct and incorrect\n",
    "    diff = avg_correct - avg_incorrect\n",
    "\n",
    "    # Plot the norm of the difference across layers\n",
    "    layer_norms = np.linalg.norm(diff, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(layer_norms)\n",
    "    plt.title(\"Difference between correct and incorrect predictions across layers\")\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"L2 Norm of difference\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example: Visualize Hidden States for a Specific Question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a question ID\n",
    "question_ids = list(hidden_data['hidden_states'].keys())\n",
    "if question_ids:\n",
    "    qid = question_ids[-1]\n",
    "\n",
    "    # Get the question metadata and hidden states\n",
    "    metadata = hidden_data['metadata'][qid]\n",
    "    hidden_state = hidden_data['hidden_states'][qid]\n",
    "\n",
    "    print(f\"Question: {metadata['question']}\")\n",
    "    print(f\"Answer: {metadata['answer']}\")\n",
    "    print(f\"Subject: {metadata['subject']}\")\n",
    "    print(f\"Hidden state shape: {hidden_state.shape}\")\n",
    "\n",
    "    # Get the Likert prediction\n",
    "    if qid in likert_results:\n",
    "        likert_result = likert_results[qid]\n",
    "        print(f\"Prediction: {likert_result['pred_label']}\")\n",
    "        print(f\"Score: {likert_result['score']}\")\n",
    "        print(f\"Probabilities: {likert_result['probs_norm']}\")\n",
    "\n",
    "    # Visualize the hidden state activations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(hidden_state, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Activation')\n",
    "    plt.title(f\"Hidden State Activations for Question {qid}\")\n",
    "    plt.xlabel(\"Hidden Dimension\")\n",
    "    plt.ylabel(\"Layer\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abstainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
